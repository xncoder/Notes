* The Org Mode
** Visibility Cycling
   [TAB] org-cycle
   [S-TAB] org-global-cycle
** Heading Motion
   C-c C-n: next heading
   C-c C-p: previous heading
   C-c C-f: next heading same level
   C-c C-b: previous heading same level
   C-c C-u: backward to higher heading
** Structure Editing...
*** insert
   M-RET: insert a heading, item or row
   C-RET: insert a new heading at the end of the current subtree
   M-S-RET: insert a todo heading
   C-S-RET: insert a todo heading
*** level promote and demote
   M-Left : promote current heading one level
   M-Right: demote current heading one level
   M-S-Left: promote current subtree one level
   M-S-Right: demote current subtree one level
*** subtree moving
   M-Up: move subtree up
   M-Down: move subtree down   
*** subtree mark,copy,cut and paste
   C-c @: mark current subtree
   C-c C-x C-w: cut current subtree
   C-c C-x M-w: copy current subtree
   C-c C-x C-y: yank subtree
** Sparse Trees
   C-c /  : promote sparse trees command
   C-c / r : regex sparse trees 
** Plain List
   
* The Go Programming Language
** The Basic 
** Golang IO
   [[https://medium.com/learning-the-go-programming-language/streaming-io-in-go-d93507931185][Golang IO]]
** Golang Book Resources...
   [[https://github.com/dariubs/GoBooks][Go Lang book resource]]
** Golang and Cocurrent Programming...
*** goroutines and channels(communicating sequential pocesses)
   1. unbuffered channels
   unbuffered channels is just synchronous channels
* Distibute Systems...
  [[https://www.toptal.com/big-data/consistent-hashing][Consistent Hasing]]
  [[http://www.aosabook.org/en/distsys.html][Scalable Web Architecture and Distributed Systems]]
** hacking openvms distibute locking system
** ecdt and coreos
* Something About Design...
** foudation:
   the design of everyday things
   emotional design
** research
   the user experience team of one
   just enough research
** Brand/Marketing
   Emotional Branding
   Ogilvy on Advertisings
   Positioning: The Battle for you mind
** Interactive Design
   Designing the obvious
   GUI bloopers 2.0
   Don't make me think
   Sketching User Experiences
* SQL and Database
** Create a new user in a MySQL server:
     create user 'hjiang'@'localhost' identified by 'jiang186212';
   then add some databases to this user:
     grant all privileges on bank.* to 'hjiang'@'localhost';
   then attatch to some database:
     use bank;
** Load a .SQL file into MySQL
   1. attach to a database:
      use bank;
   2. source the .SQL file:
      source C:\LearningSQLExample.sql
** Using MySQL command line tool:
   1. specifying a username and a database
   mysql -u hjiang -p passwd bank
   2. data and time
   select now()
** MySQL datatypes:
   1. character data:
     char(20): fix 20 len,
     varchar(20): variable 20 len,
   2. character set:
     varchar(20) character set utf8 --> set one column to utf8
     create database foreign_sales character set utf8; --> create a utf8 database
   3. numeric data:
     | Type      | Signed Range                                            | unsigned range                  |
     |-----------+---------------------------------------------------------+---------------------------------|
     | Tinyint   | −128 to 127                                             | 0 to 255                        |
     | Smallint  | −32,768 to 32,767                                       | 0 to 65,535                     |
     | Mediumint | −8,388,608 to 8,388,607                                 | 0 to 16,777,215                 |
     | Int       | −2,147,483,648 to 2,147,483,647                         | 0 to 4,294,967,295              |
     | Bigint    | −9,223,372,036,854,775,808 to 9,223,372,036,854,775,807 | 0 to 18,446,744,073,709,551,615 |
   4. float number:
     | Type        | Numeric range                                                                                               |
     |-------------+-------------------------------------------------------------------------------------------------------------|
     | Float(p,s)  | −3.402823466E+38 to −1.175494351E-38 and 1.175494351E-38 to 3.402823466E+38                                 |
     | Double(p,s) | −1.7976931348623157E+308 to −2.2250738585072014E-308 and 2.2250738585072014E-308 to 1.7976931348623157E+308 |
   5. Temporal Data:
     | Type      | Default format      | Allowable values                           |
     |-----------+---------------------+--------------------------------------------|
     | Date      | YYYY-MM-DD          | 1000-01-01 to 9999-12-31                   |
     | Datetime  | YYYY-MM-DD HH:MI:SS | 1000-01-01 00:00:00 to 9999-12-31 23:59:59 |
     | Timestamp | YYYY-MM-DD HH:MI:SS | 1970-01-01 00:00:00 to 2037-12-31 23:59:59 |
     | Year      | YYYY                | 1901 to 2155                               |
     | Time      | HHH:MI:SS           | −838:59:59 to 838:59:59                    |

     grant all privileges on test.* to 'hjiang'@'localhost';
   
* Redis
** Redis Config...
  1. check all configs on current Redis Server:
     CONFIG GET *
  2. update configurations:
     CONFIG SET loglevel "notice"
** Redis Data Types...
  1. keys:
     binary safe(you can use any binary sequence as a key)
     some tips about keys:
     a. Very long keys is not a good idea;
     b. Very short keys is not a good idea;
     c. Try stick with a shcema;
     d. The max allow key size is 512MB

  2. Strings:
     Redis string type is the simplest type of value you can associate with a Redis key
   | set | SET name "hjiang" |
   | get | GET name          |

  3. Hashes:
   Redis Hashes are maps between string fields and string values
   | set | hmset test name sex age "hjiang" "M" 23 |
   | get | hgetall test                            | 

   Some Commands on Hashes:
   
  4. Lists: 
   Redis list are lists of strings, sorted by insert order.
   User can add on the list head or the tail.
   | push | lpush test-list "string1" |
   | push | lpush test-list "string2" |
   | push | lpush test-list "string3" |
   | look | lrange test-list 0 10     |

  5. Sets:
   Redis Sets are an unordered collection of strings.
   |----------------------------------------------|
   | redis 127.0.0.1:6379> sadd name-set "hjiang" |
   | redis 127.0.0.1:6379> sadd name-set "xiaomi" |
   | redis 127.0.0.1:6379> sadd name-set "james"  |
   | redis 127.0.0.1:6379> sadd name-set "hjiang" |
   | redis 127.0.0.1:6379> smembers name-set      |
   | 1) "xiaomi"                                  |
   | 2) "james"                                   |
   | 3) "hjiang"                                  |

  6. Sorted Sets:
   members of Sorted sets are unique, but scores can repeat
   |-----------------------------------------------------|
   | redis 127.0.0.1:6379> zadd sort-set 1 "hjiang"      |
   | redis 127.0.0.1:6379> zadd sort-set 2 "heng"        |
   | redis 127.0.0.1:6379> zadd sort-set 2 "jiangheng"   |
   | redis 127.0.0.1:6379> zrangebyscore sort-set 0 1000 |
   | 1) "hjiang"                                         |
   | 2) "heng"                                           |
   | 3) "jiangheng"                                      |
   | redis 127.0.0.1:6379> zadd sort-set 0 "xiaomi"      |
   | redis 127.0.0.1:6379> zrangebyscore sort-set 0 1000 |
   | 1) "xiaomi"                                         |
   | 2) "hjiang"                                         |
   | 3) "heng"                                           |
   | 4) "jiangheng"                                      |

  7. BitMap:
   a) constant time single bit operations
   b) operations on group of bits
   cons: provide extreme space savings when storing information

** Lua and Redis...
** Golang and Redis...
   1. connect to a redis-server
#+NAME: 
#+BEGIN_SRC go 
   import "github.com/go-redis/redis"
   
   redisdb := redis.NewClient(&redis.Options{
		Addr: "localhost:6379", //default address
		Password: "",           //no passwd set
		DB:       0,            //use default db
	})

	pong, err := redisdb.Ping().Result()
	fmt.Println(pong, err)
#+END_SRC
   
* Amzaon AWS
** User:
   hjiangsse
   Jiang186212
* Common Lisp
** QuickLisp and Library transplant
  1. copy ~/quicklisp/ to Dest mechine(windows home dir)
  2. copy ~/.sbclrc to Dest mechine(windows home dir)
  3. restart sbcl, then quicklisp is auto loaded into sbcl next time
  4. (ql:quickload "xxxxx")
     tips: xxxxx must already in ~/quicklisp/dists/quicklisp/installed 
** Format
#+NAME: 
#+BEGIN_SRC lisp

#+END_SRC
* Etcd
** Start and Install
etcd is designed to reliably store infrequently updated data and provide reliable watch queries. 
etcd exposes previous versions of key-value pairs to support inexpensive snapshots and watch history events (“time travel queries”). 
A persistent, multi-version, concurrency-control data model is a good fit for these use cases.

./bin/etcd 
curl -L http://127.0.0.1:2379/versison
** key space operations
docs: 
[[https://coreos.com/etcd/docs/latest/v2/api.html#atomically-creating-in-order-keys][communicating with etcd V2]]
*** Setting the value of key:
    command:
    curl http://127.0.0.1:2379/v2/keys/message -XPUT -d value="Hello world"

    etcd return:
    {
        "action":"set",              //the action of the request we just made
        "node":{ 
            "key":"/message",        //the http path which the rquest was made
            "value":"Hello world",   //the value of the key after resolving the request
            "modifiedIndex":4,       //unique, monotonically-incrementing integer created for each change to etcd
            "createdIndex":4         //unique, monotonically-incrementing integer created for each change to etcd
         }
     }
*** etcd http header:
    command:
    curl http://127.0.0.1:2379/v2/keys/message -I

    etcd return:
    HTTP/1.1 200 OK
    Content-Length: 100
    Access-Control-Allow-Headers: accept, content-type, authorization
    Access-Control-Allow-Methods: POST, GET, OPTIONS, PUT, DELETE
    Access-Control-Allow-Origin: *
    Content-Type: application/json
    Date: Fri, 12 Apr 2019 05:39:32 GMT
    Keep-Alive: timeout=58
    X-Etcd-Cluster-Id: cdf818194e3a8c32
    X-Etcd-Index: 4
    X-Raft-Index: 5
    X-Raft-Term: 2

*** get the value of a key:
    command:
    curl http://127.0.0.1:2379/v2/keys/message

    etcd return:
    {"action":"get","node":{"key":"/message","value":"Hello world","modifiedIndex":4,"createdIndex":4}}

*** change the value of a key:
    You can change the value of /message from "hello world" to "hello etcd" with another PUT request:
    command:
    curl http://127.0.0.1:2379/v2/keys/message -XPUT -d value="Hello hjiang"

    etcd return:
    {
        "action":"set",
        "node":
            {"key":"/message",
            "value":"Hello hjiang",
            "modifiedIndex":5,
            "createdIndex":5},
         "prevNode":
            {"key":"/message",
             "value":"Hello world",
             "modifiedIndex":4,
             "createdIndex":4}
     }

*** delete a key
    command:
    curl http://127.0.0.1:2379/v2/keys/message -XDELETE

    etcd return:
    {
        "action":"delete",
        "node":{
            "key":"/message",
            "modifiedIndex":6,
            "createdIndex":5},
        "prevNode":{
            "key":"/message",
            "value":"Hello hjiang",
            "modifiedIndex":5,
            "createdIndex":5}
     }

*** using key TTL
    Keys in etcd can be set to expire after a specified number of seconds. 
    You can do this by setting a TTL (time to live) on the key when sending a PUT request:

    command:
    curl http://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -d ttl=5

    etcd return:
    {
        "action":"set",
        "node":
            {"key":"/foo",
             "value":"bar",
             "expiration":"2019-04-12T05:55:24.483911539Z",
             "ttl":5,
             "modifiedIndex":7,
             "createdIndex":7}
    }

    after 5 seconds you send a GET request:
    {
        "errorCode":100,
        "message":"Key not found",
        "cause":"/foo",
        "index":8
    }

    you can unset a TTL for a key:
    curl http://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -d ttl= -d prevExist=true
    this command only valid before TTL expiried

    etcd return:
    {
        "action":"update",
        "node":
         {"key":"/foo",
         "value":"bar",
         "modifiedIndex":10,
         "createdIndex":9},
        "prevNode":
         {"key":"/foo",
          "value":"bar",
          "expiration":"2019-04-12T06:03:26.911069511Z",
          "ttl":1,
          "modifiedIndex":9,
          "createdIndex":9}
     }
*** refreshing key TTL:
    curl http://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -d ttl=20
    curl http://127.0.0.1:2379/v2/keys/foo -XPUT -d ttl=5 -d refresh=true -d prevExist=true
*** waiting for a change:
    On terminal 1, send a GET with wait=true:
    curl http://127.0.0.1:2379/v2/keys/foo?wait=true:, this will waiting for any changes at path /foo

    On terminal 2, we set a key /foo with value "bar":
    curl http://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar

    Now, the two terminal will get the same result:
    {
        "action":"set",
        "node":
        {
            "key":"/foo",
            "value":"bar",
            "modifiedIndex":22,
            "createdIndex":22
        }
    }

*** atomically creating in-order keys
   Command 1:
   curl http://127.0.0.1:2379/v2/keys/queue -XPOST -d value=Job1

   ETCD RETURN:
   {
       "action":"create",
       "node":
       {
           "key":"/queue/00000000000000000023",
           "value":"Job1",
           "modifiedIndex":23,
           "createdIndex":23
       }
   }

   command 2:
   curl http://127.0.0.1:2379/v2/keys/queue -XPOST -d value=Job2

   ETCD RETURN:
   {
       "action":"create",
       "node":
       {
           "key":"/queue/00000000000000000024",
           "value":"Job2",
           "modifiedIndex":24,
           "createdIndex":24
       }
   }

** vagrant and etcd...
** install vagrant and Virtualbox
1. Download the latest virtualbox then install:
   sudo dpkg -i virtualbox-6.0_6.0.4-128413~Ubuntu~bionic_amd64.deb

2. sudo apt-get install vagrant
** Vagrant Boxes:
*** install a box:
vagrant box add hashicorp/precise64

result:
==> box: Loading metadata for box 'hashicorp/precise64'
    box: URL: https://vagrantcloud.com/hashicorp/precise64
This box can work with multiple providers! The providers that it
can work with are listed below. Please review the list and choose
the provider you will be working with.

1) hyperv
2) virtualbox
3) vmware_fusion

Enter your choice: 2
==> box: Adding box 'hashicorp/precise64' (v1.1.0) for provider: virtualbox
    box: Downloading: https://vagrantcloud.com/hashicorp/boxes/precise64/versions/1.1.0/providers/virtualbox.box
==> box: Successfully added box 'hashicorp/precise64' (v1.1.0) for 'virtualbox'!
*** using a box:
config our project use it as a base

Vagrant.configure("2") do |config|
  config.vm.box = "hashicorp/precise64"
*** up and ssh:

** Static initialize a etcd cluster:
* GoLang
** log(logrus)
*** logrus or log rotate
    logrus--->hook--->github.com/lestrrat/go-file-rotatelogs
*** logrus hooks
#+NAME: 
#+BEGIN_SRC go
package main

import (
	"github.com/sirupsen/logrus"
)

//A user defined hook
type Hook struct {
	name string
}

func NewHook(name string) (h *Hook) {
	return &Hook{name}
}

func (hook *Hook) Fire(entry *logrus.Entry) (err error) {
	entry.Data["appName"] = "MyApp"
	return nil
}

func (hook *Hook) Levels() []logrus.Level {
	return logrus.AllLevels
}

func init() {
	logrus.AddHook(NewHook("test"))
}

func main() {
	logrus.WithFields(logrus.Fields{
		"animal": "dog",
		"age":    "10",
	}).Info("This dog is ten years old now!")
}
#+END_SRC
*** 日志级别,日志分割,日志分发
** protobuff and go
why we use protobuff in go?
1. you can use gobs to serialize go data structure, but it
is specific in a go-env, you can not share data for other platform

2. XML is so big and heavy.
------------------------
*** install protobuf on ubuntu
#+NAME:
#+BEGIN_SRC bash
# Make sure you grab the latest version
curl -OL https://github.com/google/protobuf/releases/download/v3.7.1/protoc-3.7.1-linux-x86_64.zip

# Unzip
unzip protoc-3.7.1-linux-x86_64.zip -d protoc3

# Move protoc to /usr/local/bin/
sudo mv protoc3/bin/* /usr/local/bin/

# Move protoc3/include to /usr/local/include/
sudo mv protoc3/include/* /usr/local/include/

# Optional: change owner
sudo chwon hjiang /usr/local/bin/protoc
sudo chwon -R hjiang /usr/local/include/google
#+END_SRC
*** compile your protocol buffers
go get -u github.com/golang/protobuf/protoc-gen-go
protoc -I=$SRC_DIR --go_out=$DST_DIR $SRC_DIR/addressbook.proto
*** use protobuf in golang:
#+NAME:
#+BEGIN_SRC go
package main

import (
	pb "./tutorial"
	"fmt"
	proto "github.com/golang/protobuf/proto"
	"io/ioutil"
	"log"
)

func main() {
	p1 := pb.Person{
		Id:    1234,
		Name:  "John Doe",
		Email: "jdoe@example.com",
		Phones: []*pb.Person_PhoneNumber{
			{Number: "555-4321", Type: pb.Person_HOME},
		},
	}

	p2 := pb.Person{
		Id:    1235,
		Name:  "hjiang",
		Email: "hjiang@sse.com.cn",
		Phones: []*pb.Person_PhoneNumber{
			{Number: "555-4320", Type: pb.Person_HOME},
		},
	}

	book := pb.AddressBook{
		People: []*pb.Person{
			&p1, &p2,
		},
	}

	//write the new address book to disk
	out, err := proto.Marshal(&book)
	if err != nil {
		log.Fatalln("Failed to encode address book:", err)
	}

	if err := ioutil.WriteFile("./addressbook.txt", out, 0664); err != nil {
		log.Fatalln("Failed to write address book:", err)
	}

	//read the address book back
	in, err := ioutil.ReadFile("./addressbook.txt")
	if err != nil {
		log.Fatalln("Failed to reading file:", err)
	}

	readed_book := &pb.AddressBook{}
	if err := proto.Unmarshal(in, readed_book); err != nil {
		log.Fatalln("Failed to parse address book:", err)
	}

	fmt.Println(*readed_book)
}
#+END_SRC
** emacs gocode install:
* Kafka


